// Tools of AI - SDU Robotics
// Intelligent LUDO player using Q-Learning
// Carlos Viescas Huerta


#include "Q_player.h"

using namespace std;
using namespace cv;


/*

	Q-LEARNING ALGORITHM:
	
		1. Split the game into discrete set of States & Actions.
		2. Create Q-Table.
		3. State representation.
		4. Define rewards.
		5. Update Q-values using the learning formula:
			delta_Q(s,a) = alpha * ( r + gamma * max[a1]Q(s1, a1) - Q(s,a) )
		6. Action Selection.

*/


//-----------------------------------------------------------------

// Q_player object constructor.
Q_player::Q_player()//: pos_start_of_turn(16), pos_end_of_turn(16), dice_roll(0)
{
	// Load and initialize Q-table
	acc = 0;
	FileStorage fs("/home/charlie/workspace/AI/LUDO-ToAI/ludo/genfiles/Q_Table.xml", FileStorage::READ);
	fs["Q_table"] >> Q_table;
	fs.release();
	// Display Q-table.
	cout << "Q-Learning Table (rows = " << Q_table.rows << ", columns = " << Q_table.cols << "):" << endl;
	cout << Q_table << endl;
	
	//update = false;	
	
}// Q_player()



//------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


// 3. STATE REPRESENTATION


// Representation of states. Binary state-indicator:
/*

	1. Home		 	--> 		state = 0
	2. On free spot		-->		state = 1
	3. On star		-->		state = 2
	4. On globe		-->		state = 3
	5. Shield wall		-->		state = 4
	6. Red carpet		-->		state = 5
	7. On goal 		-->		state = 6

*/

// This function calculates the current state for each token the player has. Requires board spot number.
// Board positions:
/*
	Home: -1
	Stars: 5, 11, 18, 24, 31, 37, 44, 50 
	Globes: 0, 8, 13, 21, 26, 34, 39, 47
	Red Carpet: from 50 to 56
	Hitting 50 goes to goal directly
		
*/
vector<int> Q_player::state()
{
	int state = 0;
	vector<int> states;
	
	cout << "---- states ----" << endl;

	for( int z=0; z<4; z++)
	{
		int board_position = pos_start_of_turn[z];

		// Check if we are in home
    		if(board_position == -1)
    		{

        		state = 0;
        		cout << "Token #" << z << " in jail" << endl;
	
    		} // if -1
	
		// Check if we are in a star
		if(board_position == 5 || board_position == 11 || board_position == 18 || board_position == 24 || board_position == 31 || board_position == 37 || board_position == 44 || board_position == 50)
 	   	{
 		       	state = 2;
 		       	cout << "Token #" << z << " on Star. Board position: #" << board_position << endl;

 	   	} // if star

		// Check if we are a globe
		if(board_position == 8 || board_position == 13 || board_position == 21 || board_position == 26 || board_position == 34 || board_position == 39 || board_position == 47 || board_position == 0)
 	   	{
 		       	state = 3;
 		       	cout << "Token #" << z << " on globe. Board position: #" << board_position << endl;

 	   	} // if globe

		// Check if we are in goal
		if(board_position == 99 || board_position == 56)
    		{
       			state = 6;
        		cout << "Toke #" << z << " in Goal!!!" << endl;

    		} // if goal

		// Check if we are in the Red Carpet
		if(board_position > 50 && board_position < 56)
    		{
        		state = 5;
        		cout << "Token #" << z << " on the Red Carpet. Keep pushing!!" << endl;

		} // if Red Carpet
		
	
		// Check if we are forming a wall with other token and therfore, safe
		if(board_position != -1 && board_position != 99)
    		{
        		if(((board_position == pos_start_of_turn[0])  && (z != 0)) || ((board_position == pos_start_of_turn[1]) && (z != 1)) || ((board_position == pos_start_of_turn[2]) && (z != 2)) || ((board_position == pos_start_of_turn[3]) && (z != 3)))
        		{
				// Activate 'Shield wall' input
        	   		state = 4;

				if(state == 5) // Red Carpet
				{
        	        		state = 5;
        	    		} // if 4	
            
				cout << "Token #" << z << " ¡¡¡¡ Shield Wall !!!! Board position: #" << board_position << endl;
		
			} // if board_position && !token

		} // if !=-1 && !=99

		// Check if we are just in a regular position
		if(state != 0 && state != 2 && state != 3 && state != 4 && state != 5 && state != 6)
    		{
        		cout << "Token #" << z << " on free spot. Board position: #" << board_position << endl;
        		state = 1;
		} // if free spot

		// Check for errors
		if (state < 0 || state > 6)
		{
			cout << "An error ocurred when getting the state." << endl;		
			exit(0);
			
		}// if

		states.push_back(state);	
	
	}// for z
	cout << "---- states ----" << endl << endl;
	return states;

}// current_state()




// This function analizes the game after throwing the dice and calculates all the possible moves (actions) to be taken.
// Binary action-indicator
/*

	1. Home breakout		-->		move = 1 
	2. No possible move		-->		move = 0
	3. Regular move			--> 		move = 2
	4. Move to star			-->		move = 3
	5. Move to globe	 	-->		move = 4
	6. Form a Shield Wall		-->		move = 5
	7. Enter the Victory Road	-->		move = 6
	8. Commit suicide		-->		move = 7
	9. Kill oponent			-->		move = 8
	10. Make it to goal		-->		move = 9

*/
vector<int> Q_player::get_possible_moves(int dice)
{
	
	int idx = -1; // Index = board_postion + dice; Shows where can we go
	int move = 0;
	vector<int> moves;
	
	cout << "---- moves ----" << endl;

	// Calculate moves for each token
	for (int i; i<4; i++)
	{
		int board_position = pos_start_of_turn[i];
		
		// no move
		if(board_position == -1 && dice != 6)
		{
			move = 0;
			cout << "Token #" << i << " trapped in jail with no possible move" << endl;
		}// if no move

		if(board_position == 99)
		{
			move = 0;
			cout << "Token #" << i << " is already in goal :)" << endl;
		}// if no move			

		// Jailbreak
		if(board_position == -1 && dice == 6)
		{
			move = 1;
			cout << "Token #" << i << " Jailbreak!!" << endl;
			
		}// if -1

		// if token is in game
		if(board_position != -1 && board_position != 99)
		{
			idx = board_position + dice;

			// Goal
			if(idx == 56)
			{
				move = 9;
				cout << "Token #" << i << " Moving to goal!!" << endl; 
			}// if goal 56

			if(idx == 50 && board_position >= 44 && board_position < 50)
			{
				move = 9;
				cout << "Token #" << i << " Moving to goal!!" << endl; 
			}// if goal 50

			// stars
			if(idx == 5 || idx == 11 || idx == 18 || idx == 24 || idx == 31 || idx == 37 || idx == 44)
			{	
				move = 3;
				cout << "Token #" << i << " Moving to star on position #" << idx << endl;
			}//if stars

			// shield wall
			for(int j=0; j<4; j++)
			{
				if(i != j && idx == pos_start_of_turn[j] && pos_start_of_turn[j] != 99)
				{
					move = 5; 
					cout << "Token #" << i << " SHIELDWALL with token #" << j << " in position #" << idx << endl;
					break;
				}// if 
			}// for

			bool killer = false;
			bool dumbass = false;
			
			// Meeting other player's token
			for( int h=4; h<16; h++)
			{
				// Check if there is someone in idx
				if( idx == pos_start_of_turn[h] )
				{
					// Check if idx is a globe (then suicide)
					if( idx == 8 || idx == 13 || idx == 21 || idx == 26 || idx == 34 || idx == 39 || idx == 47)
					{
						dumbass = true;	
						cout << "Token #" << i << " commited suicide in globe #" << idx << endl;
						break;
					} // if globe

					// Check if the oponent was in shieldwall
					for(int k=0; k<4; k++)
					{
						int tkn = int(h/4) * k;
						if( idx == pos_start_of_turn[tkn] && tkn != h)
						{
							dumbass = true;
							cout << "Token #" << i << " suicide in position #" << idx << endl;
						}// if shieldwall
						
					}// for
						
					killer = true;
					cout <<  "Token #" << i << " killing that son of a bitch #" << h << " in position #" << idx << endl;
					
				}// if meeting people
			}// for

			if(killer == true)
			{
				move = 8;
			}// if killer
			
			if(dumbass == true)
			{
				move = 7;
			}// if dumbass

			// Move to globe
			if( (idx == 8 || idx == 13 || idx == 21 || idx == 26 || idx == 34 || idx == 39 || idx == 47) && dumbass == false)
			{
				move = 4;	
				cout << "Token #" << i << " in globe #" << idx << endl;
			}// if globe

			// Victory Road
			if(idx > 50 && idx < 56)
			{
				move = 6;
				cout << "Token #" << i << " in the Victory Road #" << idx << endl; 
			}// if Victory

			
			if( move != 0 && move != 1 && move != 3 && move != 4 && move != 5 && move != 6 && move != 7 && move != 8 && move != 9 )
			{
				move = 2;
				cout << "Token #" << i << " just moving to position #" << idx << endl;
			}// regular move

		}// if token is in game

		if( move < 0 || move > 9)
		{
			cout << "An error ocurred when getting moves." << endl;
			exit(0);		
		}
			
		moves.push_back(move);

	}// for int i (tokens)

	cout << "---- moves ----" << endl << endl;

	return moves;

}// get_possible_moves()


// Funtion that creates the playmaker function (contains token, state and move) 
vector<tuple<int, int, int>> Q_player::play_maker(vector<int> states, vector<int> moves)
{
	vector<tuple<int,int,int>> PM;
	
	for(int i=0; i<4; i++)
	{
		PM.push_back(make_tuple(i, states[i], moves[i]));
	}// for	

	return PM;

}// play_maker()


double Q_player::assign_reward(int performed_action, int previous_position, int current_position, int previous_state, int current)
{
	double reward = 0;
	int goal = 56;
	static int games = 0;

	// Add two new rewards: Gettin' closer to goal and getting in VR
	if( previous_position == -1 && current_position != -1 && previous_position != 99 && current_position != 99 )
	{
		// Advancing towards goal
		if( current_position != previous_position && current_position > previous_position )
		{
			reward += 0.25;
		}// reward for moving towards goal.

		// Penalization for getting far of the goal
		if( (goal - previous_position) < (goal - current_position) )
		{
			reward -= 0.05;
		}// penalization
	
		// Penalization for not moving
		if( performed_action == 0 && previous_position == current_position && previous_state == current)
		{
			reward -= 0.8;
		}// no moving

		// Reward for entering the Victory road
		if( performed_action == 6 && previous_position < 50)
		{
			reward += 0.1;
		}

		// Reward for getting out of home	
		if(performed_action == 1 && previous_position == -1 && current_position == 0)
    		{
        		reward += 0.25;
    		}//if

		// Reward for killing
		if(performed_action == 8)
		{
			reward += 0.1;
		}//if

		// Form shieldwall
		if(performed_action == 5)
		{
			reward += 0.05;
		}//if
	
		// Sending a token to goal
		if(performed_action == 9)
		{
			reward += 1.5;
		}//if
	
		// Suiciding
		if(performed_action == 8)
		{
			reward -= 0.7;
		}//if
	
		// Getting a token killed
		for(int i=0; i<4; i++)
		{
			if(pos_end_of_turn[i] != -1 && pos_start_of_turn[i] == -1)
			{
				reward -= 0.5;
			}// if
		}// for i

		cout << "Before considering winning" << endl;

		// Winning game
		bool winning = true;
		for(int j=0; j<4; j++)
		{
			if(pos_end_of_turn[j] != 99)
			{
				winning = false;
			}// if
		}// for j
	
		if(winning == true)
		{
			reward += 5;
			games++;
		}
	
		// Losing the game
		bool loosing_yellow = true;
		for(int h=4; h<8; h++)
		{
			if(pos_end_of_turn[h] != 99)
			{
				loosing_yellow = false;
			}// if
		}// for j
	
		bool loosing_bleu = true;
	
		for(int k=8; k<12; k++)
		{
			if(pos_end_of_turn[k] != 99)
			{
				loosing_bleu = false;
			}// if
		}// for j
	
		bool loosing_red = true;
	
		for(int l=12; l<16; l++)
		{
			if(pos_end_of_turn[l] != 99)
			{
				loosing_red = false;
			}// if
		}// for j
	
		if( loosing_yellow == true ||  loosing_bleu == true || loosing_red == true )
		{
			reward -= 3;
			games++;
		}

		cout << "Out of rewards" << endl;

	}// if we are in play

	return reward;

}// assign_reward()


// Update Q_table values
void Q_player::update_Q_table(tuple<int,int,int,int> player_state_action_i, int current)
{
	cout << endl << "UPDATE Q_TABLE" << endl << endl;

	double alfa = 0.7; // Learning rate € [0, 1]
    	double gamma = 0.3; // Discount factor € [0, 1]
	
	cout << "Learning rate = " << alfa << ";  Discount factor = " << gamma << endl;    

	int player_played_i = get<0>(player_state_action_i);
    	int previous_state = get<1>(player_state_action_i);
    	int performed_action = get<2>(player_state_action_i);
    	int previous_position = get<3>(player_state_action_i);
    	int current_position = pos_start_of_turn[player_played_i];
    
	cout << "Previous position: "<< previous_position << endl;
    	cout << "Current position: "<< current_position << endl;    	

    	//int current_player_state = current[0];
    	double reward = assign_reward(performed_action, previous_position, current_position, previous_state, current);
    		
	acc += reward; 
    	
   	cout << "Immediate Reward: " << reward << endl;
	cout << "Accumulated: "<< acc << endl;


    	double max = -10000000000000;
    	for(int i = 0; i < 11 ;  i++)
    	{
        	//cout << current_player_state << " " << i << endl;
        	double test = Q_table.at<float>(current, i);
        	if(test > max)
        	{
        		max  = i;
        	}
    	}

   	cout << "Previous state: " << previous_state  << endl;
    	cout << "Action taken: " << performed_action << endl;
    	
    	Q_table.at<float>(previous_state, performed_action) += alfa * (reward + gamma * max - Q_table.at<float>(previous_state, performed_action));
    	
	cout << endl << "Q-TABLE UPDATED" << endl << endl;

}// update_Q_table()


//---------------------------------------------------------------------------------------------------------------------


// This will require update
int Q_player::make_decision()
{
	cout << endl << "MAKE DECISION" << endl;

	int hh = get<0>(player_state_action_previous_position);

	cout << "Update game-state." << endl;
	cout << "Dice roll (twist of fate): " << dice_roll << endl;
        cout << "previous Token moved: #" << hh << endl;
	cout << "Previous move: " << std::get<2>(player_state_action_previous_position) << endl;        
	cout << "Previous state: " << get<1>(player_state_action_previous_position) << endl;
	

	vector<int> states = Q_player::state();
	vector<int> movements = Q_player::get_possible_moves(dice_roll);

	cout << "Current state of token #" << hh << ": " << states[hh] << endl;        

	update_Q_table(player_state_action_previous_position, states[hh]);
       	player_state_action.clear();

        
        FileStorage fs("/home/charlie/workspace/AI/LUDO-ToAI/ludo/genfiles/Q_Table.xml", FileStorage::WRITE);
        fs << "Q_table" << Q_table;
	fs.release();
        	
	cout << "table saved" << endl;
	
	
	//vector<int> states = Q_player::state();
	//vector<int> movements = Q_player::get_possible_moves(dice_roll);
	vector<tuple<int,int,int>> token_i = Q_player::play_maker(states, movements);
  	player_state_action.insert(player_state_action.end(), token_i.begin(), token_i.end());

	for(int v = 0 ; v < 4 ; v++)
    	{
        	if(pos_start_of_turn[v] >=-1 && pos_start_of_turn[v] < 99) // Maybe the if should be changed with no end limit
        	{
            		cout << "Player token " << v << " with pos " << pos_start_of_turn[v] << endl;

            		// Action and state
        		
            		cout << "Token #" << v << endl;
            		cout << "Start position: " << pos_start_of_turn[v] << endl;
            		cout << "dice_roll: "<< dice_roll << endl;

            		cout << "Current state: " << states[v] << endl;	
            		cout << "Posible moves: " << movements[v] << endl;
        	}// if

    	}// for
	
	//update == false;
	cout << "Size after all tokens: "<< player_state_action.size() << endl;

    	if(player_state_action.size() > 4)
    	{
        	cout << "something wrong!!" << endl;
        	exit(0);
    	}
    	
	cout << "Gonna make decision" << endl;

	double epsilon = 0.2;
	player_state_action_previous_position = e_greedy(epsilon); // 70% explotation, 30% exploration.

    	cout << "Player: " << player_played << " In state: " << get<1>(player_state_action_previous_position) << " Peforms action: " << get<2>(player_state_action_previous_position) << endl;

	cout << endl << "DECISION MADE" << endl << endl;	
    
	return player_played;

} // make_decision()


// E-Greedy: Choose randomly with probability E, otherwise greedy.
tuple<int, int, int, int> Q_player::e_greedy(double eps)
{
	cout << endl << "E_GREEDY LEARNING" << endl << endl;

	// Set e-greedy probability	
	double limit  = eps*100;

	cout << "Exploration rate = " << limit << "%  |  Explotation rate =  " << 100-limit << "%" << endl;
	
    	random_device rd;
    	mt19937 mt(rd());
    	uniform_int_distribution<int> dist(1 , 100);

   	// Random action
	if(dist(mt)< limit)
	{
        	int firstPlayer = get<0>(player_state_action[0]);
	       	int lastPlayer = get<0>(player_state_action[player_state_action.size() -1]);
	       	cout << "Random decision" << endl;
        
		random_device player_r;
	        mt19937 player_mt(player_r());
	        uniform_int_distribution<int> dist_p(firstPlayer, lastPlayer);

	        int player = dist_p(player_mt);
	        player_played = player;

	        int previous_position = pos_start_of_turn[player_played];
	        auto it = find_if(player_state_action.begin(), player_state_action.end(), [](const tuple<int,int,int>& e) {return get<0>(e) == 0;});
	        int position = distance(player_state_action.begin(),it);
	        cout << "position: " << position << endl;

	        int state = get<1>(player_state_action[position]);
	        int action = get<2>((player_state_action[position]));

	        for(unsigned int i = 0 ; i < player_state_action.size(); i++)
	        {
	            int player = get<0>(player_state_action[i]);
	            int state = get<1>(player_state_action[i]);
	            int action = get<2>(player_state_action[i]);
	            double test = Q_table.at<float>(state, action);
	            cout << test << " ";
	        }// for
		
		cout << endl;
	        cout << "Random player: " << player << " state: " << state << " Action: " << action << endl;

	        return make_tuple(player, state, action, previous_position);
	}// if

	// Greedy learned action
	else
	{	
		cout << "Greedy decision" << endl;
        	//Return max
        	double max = -1000000;
        	int position;
        	for(unsigned int i = 0 ; i < player_state_action.size(); i++)
        	{
        		int player = get<0>(player_state_action[i]);
        		int state = get<1>(player_state_action[i]);
        		int action = get<2>(player_state_action[i]);
        		double test = Q_table.at<float>(state, action);
        		cout << test;

        		if(test > max)
            		{
                		max = test;
                		position = i;
                		player_played = player;
            		}// if
 	               cout << endl;
        	}// for
        
		int previous_position = pos_start_of_turn[player_played];
	        int state = get<1>(player_state_action[position]);
	        int action = get<2>(player_state_action[position]);

	        return make_tuple(player_played, state, action, previous_position);

	}// else

	cout << endl << "E_GREEDY LEARNING" << endl << endl;

}// e_greedy()


//----------------------------------------------------------------------------------------------------



void Q_player::start_turn(positions_and_dice relative)
{
    pos_start_of_turn = relative.pos;
    dice_roll = relative.dice;
    int decision = make_decision();
    emit select_piece(decision);

}// start_turn()



void Q_player::post_game_analysis(std::vector<int> relative_pos)
{
    	pos_end_of_turn = relative_pos;
    	bool game_complete = true;
    	for(int i = 0; i < 4; ++i)
	{
        	if(pos_end_of_turn[i] < 99)
		{
        		game_complete = false;
        	}// if
    	}// for	

    emit turn_complete(game_complete);

}// post_game_analyis()
